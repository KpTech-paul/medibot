{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe24b8-318e-41aa-81e5-236b94735382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import speech_recognition as sr\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806484af-3f69-41a0-82c9-eb946478f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Load Intents ----------------\n",
    "with open(\"intents.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "patterns = []\n",
    "tags = []\n",
    "responses = {}\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        patterns.append(pattern)\n",
    "        tags.append(intent[\"tag\"])\n",
    "    responses[intent[\"tag\"]] = intent[\"responses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab9e1a-71f3-4a8a-a56f-0fb9bf53bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Paths ----------------\n",
    "MODEL_PATH = \"medibot_model.keras\"\n",
    "TOKENIZER_PATH = \"tokenizer.json\"\n",
    "LABEL_ENCODER_PATH = \"labels.npy\"\n",
    "# ---------------- Train or Load Model ----------------\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(\"Loading saved model...\")\n",
    "    model = tf.keras.models.load_model(\"medibot_model.keras\")\n",
    "\n",
    "    # Load tokenizer\n",
    "    with open(TOKENIZER_PATH, \"r\") as f:\n",
    "        tokenizer_json = f.read()   # get raw JSON string\n",
    "        tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(tokenizer_json)\n",
    "\n",
    "    # Load label encoder\n",
    "    lbl_classes = np.load(LABEL_ENCODER_PATH, allow_pickle=True)\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    lbl_encoder.classes_ = lbl_classes\n",
    "\n",
    "else:\n",
    "    print(\"Training new model...\")\n",
    "    # Tokenizer\n",
    "    tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(patterns)\n",
    "    sequences = tokenizer.texts_to_sequences(patterns)\n",
    "    padded = pad_sequences(sequences, padding=\"post\")\n",
    "\n",
    "    # Labels\n",
    "    lbl_encoder = LabelEncoder()\n",
    "    labels = lbl_encoder.fit_transform(tags)\n",
    "\n",
    "    # Model (Deep Learning)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                                  output_dim=64,\n",
    "                                  input_length=padded.shape[1]),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(len(set(tags)), activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        padded, np.array(labels), test_size=0.2, random_state=42\n",
    "    )\n",
    "    # Train\n",
    "    history = model.fit(X_train, y_train, epochs=300, verbose=1, validation_data=(X_test, y_test))\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    all_labels = list(range(len(lbl_encoder.classes_)))\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    print(classification_report(\n",
    "        y_test,\n",
    "        y_pred_classes,\n",
    "        labels=all_labels,                  # all possible label indices\n",
    "        target_names=lbl_encoder.classes_,   # corresponding names\n",
    "        \n",
    "    ))\n",
    "\n",
    "    # Save\n",
    "    model.save(\"medibot_model.keras\")\n",
    "    with open(TOKENIZER_PATH, \"w\") as f:\n",
    "        f.write(tokenizer.to_json())\n",
    "    np.save(LABEL_ENCODER_PATH, lbl_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47cd5f5d-4665-45c1-8e06-1f06bb4d134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Gemini API ----------------\n",
    "API_KEY = \"AIzaSyCPulfljNVHbBn5VzqCO0Py_y3zHDwmSxg\"\n",
    "API_URL = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={API_KEY}\"\n",
    "\n",
    "def call_gemini(user_input):\n",
    "    \"\"\"Restrict Gemini responses to heart health domain.\"\"\"\n",
    "    prompt = f\"You are a heart health assistant. Answer only health-related questions. User asked: {user_input}\"\n",
    "\n",
    "    payload = {\n",
    "        \"contents\": [\n",
    "            {\"parts\": [{\"text\": prompt}]}\n",
    "        ]\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        try:\n",
    "            return data[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "        except (KeyError, IndexError):\n",
    "            return \"Sorry, I couldnâ€™t process that.\"\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2b8aa28-f8ac-412c-8fa6-4da450815b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Chatbot ready! Type 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is capital city of Rwanda?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I am designed to answer questions about heart health. I cannot provide information about the capital city of Rwanda.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  who are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I am a heart health assistant designed to provide information and support related to cardiovascular health. I can answer questions about heart disease, risk factors, healthy lifestyle choices for your heart, and more. However, I am not a substitute for professional medical advice.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Chatbot Function ----------------\n",
    "def chatbot(user_input, threshold=0.95):\n",
    "    seq = tokenizer.texts_to_sequences([user_input])\n",
    "    padded_seq = pad_sequences(seq, maxlen=model.input_shape[1], padding=\"post\")\n",
    "    pred = model.predict(padded_seq, verbose=0)\n",
    "    tag_index = np.argmax(pred)\n",
    "    confidence = pred[0][tag_index]\n",
    "\n",
    "    if confidence >= threshold:\n",
    "        tag = lbl_encoder.inverse_transform([tag_index])[0]\n",
    "        return random.choice(responses[tag])\n",
    "    else:\n",
    "        return call_gemini(user_input)\n",
    "\n",
    "# ---------------- Voice Support ----------------\n",
    "engine = pyttsx3.init()\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def listen():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"ðŸŽ¤ Listening...\")\n",
    "        audio = recognizer.listen(source)\n",
    "        try:\n",
    "            return recognizer.recognize_google(audio)\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Sorry, I didnâ€™t understand that.\"\n",
    "        except sr.RequestError:\n",
    "            return \"Speech service unavailable.\"\n",
    "\n",
    "# ---------------- Run Chatbot ----------------\n",
    "def run_chatbot(mode=\"text\"):\n",
    "    print(\"ðŸ¤– Chatbot ready! Type 'quit' to exit.\")\n",
    "\n",
    "    while True:\n",
    "        if mode == \"text\":\n",
    "            query = input(\"You: \")\n",
    "        else:  # voice mode\n",
    "            query = listen()\n",
    "            print(\"You:\", query)\n",
    "\n",
    "        if query.lower() in [\"quit\", \"exit\"]:\n",
    "            break\n",
    "\n",
    "        answer = chatbot(query)\n",
    "        print(\"Bot:\", answer)\n",
    "\n",
    "        if mode == \"voice\":\n",
    "            speak(answer)\n",
    "\n",
    "# ---------------- Choose Mode ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_chatbot(mode=\"text\")   # or mode=\"voice\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a7242-2974-41d3-87be-0170671b46b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
